
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Contents &#8212; Math 452 Site</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]]}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Contents" href="../m4_03/m4_03.html" />
    <link rel="prev" title="Contents" href="../m4_01/m4_01.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/PSU_SCI_RGB_2C.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Math 452 Site</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome to Math 452
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  contents
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module0/ch0_.html">
   Module 0 Get started: course information and preparations:
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/ch0_1.html">
     Course information, requirements and reference
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/ch0_2.html">
     Course background and introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/ch0_3.html">
     Introduction to Python and Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module0/quiz0.html">
     Preliminary Quiz
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module1/module1_.html">
   Module 1: Linear machine learning models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_01.html">
     Machine learning basics, popular data sets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_02.html">
     Linearly separable sets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_03.html">
     Logistic regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_04.html">
     KL-divergence and cross-entropy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_05.html">
     Support vector machine and relation with LR
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_06.html">
     Optimization and gradient descent method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/m1_hw.html">
     Homework 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/Programming_Assignment_1.html">
     Module 1 Programming Assignment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module1/quiz1.html">
     Quiz 1
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module2/module2_.html">
   Module 2: Probability and training algorithms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_01.html">
     Introduction to probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_02.html">
     Probabilistic derivation of logistic regression models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_03.html">
     Convex functions and convergence of gradient descen
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_04.html">
     Stochastic gradient descent method and convergence theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_05.html">
     MNIST: training and generalization accuracy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/m2_hw.html">
     Homework 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module2/Programming_Assignment_2.html">
     Week 2 Programming Assignment
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module3/module3_.html">
   Module 3: Deep neural networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_01/m3_01.html">
     Nonlinear models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_02/m3_02.html">
     Polynomials and Weierstrass theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_03/m3_03.html">
     Finite element method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_04/m3_04.html">
     Deep neural network functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_05.html">
     Universal approximation properties
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_06.html">
     Application to data classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_07.html">
     DNN for image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/C08_DNN.html">
     Building and Training Deep Neural Networks (DNNs) with Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/m3_hw.html">
     Homework 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module3/Programming_Assignment_3.html">
     Week 3 Programming Assignment
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../module4_.html">
   Module 4: Convolutional neural networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../m4_01/m4_01.html">
     Contents
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Contents
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m4_03/m4_03.html">
     Contents
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m4_04/m4_04.html">
     Training CNN with GPU on Colab
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../m4_05.html">
     Building and Training Convolutional Neural Networks (CNNs) with Pytorch
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module5/module5_.html">
   Module 5: Normalization, ResNet and Multigrid
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_01/m5_01.html">
     Contents
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_02/m5_02.html">
     Batch normalization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_03/m5_03.html">
     Building and Training ResNet with Pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/m5_04/m5_04.html">
     Finite Element Method and Multigrid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module5/Programming_Assignment_5.html">
     Week 5 Programming Assignment
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Module6/module6_.html">
   Module 6: MgNet
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/m6_01.html">
     1D and 2D Finite Element and Multigrid
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/m6_02.html">
     Multigrid and MgNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/MG_MgNet.html">
     Multigrid and MgNet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Module6/Final_Project.html">
     MATH 497: Final Project
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/Module4/m4_02/m4_02.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Contents
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutional-neural-networks">
   Convolutional Neural Networks
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-operations">
     Convolutional operations
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#images-as-matrix">
       Images as matrix
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convolution-operation-with-one-channel">
       Convolution operation with one channel
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convolution-with-stride-one-channel">
       Convolution with stride (one channel)
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#convolutional-operations-with-multi-channel">
       Convolutional operations with multi-channel
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#pooling-operation-in-cnns">
       Pooling operation in CNNs
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolution-with-stride-s-as-pooling">
   Convolution with stride s as pooling
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#nonlinear-pooling">
   Nonlinear pooling
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#examples-of-convolution-filters-and-performance">
     Examples of convolution filters and performance
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#calculation-with-convolutions">
       Calculation with convolutions
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#image-convolution-examples">
       Image convolution examples
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#line-detection-by-1d-laplacian">
       Line detection by 1D Laplacian
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#edge-detection-by-2d-laplacian-operator">
       Edge detection by 2D Laplacian operator
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#the-laplacian-of-gaussian">
       The Laplacian of Gaussian
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#other-examples-with-relu-activation">
       Other examples with ReLU activation
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#some-other-examples">
       Some other examples
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#edge-detection">
   Edge detection
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-sobel-edge-operator">
   The Sobel Edge Operator
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simple-box-blur">
   Simple box blur
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gaussian-blur">
   Gaussian blur
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="contents">
<h1>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">¶</a></h1>
<p>1 Convolutional Neural Networks
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots \ldots \ldots\)</span></p>
<p><span class="math notranslate nohighlight">\(1.1\)</span> Convolutional operations
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots\)</span></p>
<p>1.1.1 Images as matrix
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots . . . . . . . . . . . . . . . . .\)</span></p>
<p>1.1.2 Convolution operation with one channel
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots .\)</span></p>
<p>1.1.3 Convolution with stride (one channel)
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots \ldots .\)</span></p>
<p>1.1.4 Convolutional operations with multi-channel
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots .6\)</span></p>
<p><span class="math notranslate nohighlight">\(1.1 .5\)</span> Pooling operation in CNNs
<span class="math notranslate nohighlight">\(\ldots \ldots . \ldots . . . . . . . . . . . . . . . . .\)</span></p>
<p><span class="math notranslate nohighlight">\(1.2\)</span> Examples of convolution filters and performance
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots, \ldots\)</span></p>
<p>1.2.1 Calculation with convolutions ………………………… 8</p>
<p><span class="math notranslate nohighlight">\(1.2 .2 \quad\)</span> Image convolution examples
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots . \ldots . . . . . . . . . .\)</span></p>
<p>1.2.3 Line detection by 1D Laplacian
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots . \ldots . . . . . . . . .\)</span></p>
<p>1.2.4 Edge detection by 2D Laplacian operator
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots .12\)</span></p>
<p>1.2.5 The Laplacian of Gaussian
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots . . . . . . . . . . . .\)</span></p>
<p>1.2.6 Other examples with ReLU activation
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots .15\)</span></p>
<p>1.2.7 Some other examples
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots \ldots \ldots . . . . . . . . . . . . . . . . . . .\)</span></p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-01" />{width=”\textwidth”}</p>
<p>References
<span class="math notranslate nohighlight">\(\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots\)</span></p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-02" />{width=”\textwidth”}</p>
</div>
<div class="section" id="convolutional-neural-networks">
<h1>Convolutional Neural Networks<a class="headerlink" href="#convolutional-neural-networks" title="Permalink to this headline">¶</a></h1>
<div class="section" id="convolutional-operations">
<h2>Convolutional operations<a class="headerlink" href="#convolutional-operations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="images-as-matrix">
<h3>Images as matrix<a class="headerlink" href="#images-as-matrix" title="Permalink to this headline">¶</a></h3>
<p>An image can be viewed as a piecewise constant function on a grid.
Images with different resolutions can then be viewed as functions on
grids of different sizes. The use of such multiple-grids is a main
technique used in the standard multigrid method for solving discretized
partial differential equations, and it can also be interpreted as a main
ingredient used in convolutional neural networks (CNN) for image
calssification.</p>
<p>An image can be viewed as a function on a grid [6] on a rectangle
domain <span class="math notranslate nohighlight">\(\Omega \in \mathcal{R}^{2}\)</span>. Without loss of generality, we
assume that the grid, <span class="math notranslate nohighlight">\(\mathcal{T}\)</span>, is of size
$<span class="math notranslate nohighlight">\(m=2^{s}, \quad n=2^{t}\)</span><span class="math notranslate nohighlight">\( for some integers \)</span>s, t \geq 1<span class="math notranslate nohighlight">\(. Starting
from \)</span>\mathcal{T}<em>{1}=\mathcal{T}<span class="math notranslate nohighlight">\(, we consider a sequence of coarse
grids with \)</span>J=\min (s, t)<span class="math notranslate nohighlight">\( (as depicted in Fig. 1.1.1 with \)</span>J=4)<span class="math notranslate nohighlight">\( :
\)</span><span class="math notranslate nohighlight">\(\mathcal{T}_{1}, \mathcal{T}_{2}, \ldots, \mathcal{T}_{J}\)</span><span class="math notranslate nohighlight">\( such that
\)</span>\mathcal{T}</em>{\ell}<span class="math notranslate nohighlight">\( consist of \)</span>m_{\ell} \times n_{\ell}<span class="math notranslate nohighlight">\( grid points,
with \)</span><span class="math notranslate nohighlight">\(m_{\ell}=2^{s-\ell+1}, \quad n_{\ell}=2^{t-\ell+1} .\)</span>$ Here,
please note that each element in this grid can be viewed as a pixel or
an image or an element in a matrix.</p>
</div>
<div class="section" id="convolution-operation-with-one-channel">
<h3>Convolution operation with one channel<a class="headerlink" href="#convolution-operation-with-one-channel" title="Permalink to this headline">¶</a></h3>
<p>For simplicity of exposition, we denote
$<span class="math notranslate nohighlight">\(m=m_{1}=2^{s}, \quad n=n_{1}=2^{t} .\)</span>$
<img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-04" />{width=”\textwidth”}</p>
<p>Fig. 1.1. multilevel grids for piecewise constant functions (images)</p>
<p>Definition 1. A convolution defined on <span class="math notranslate nohighlight">\(\mathbb{R}^{m \times n}\)</span> is a
linear mapping
<span class="math notranslate nohighlight">\(K *: \mathbb{R}^{m \times n} \mapsto \mathbb{R}^{m \times n}\)</span> defined
with padding, for any <span class="math notranslate nohighlight">\(g \in \mathbb{R}^{m \times n}\)</span> by:
$<span class="math notranslate nohighlight">\([K * g]_{i, j}=\sum_{p, q=-k}^{k} K_{p, q} g_{i+p, j+q}, \quad i=1: m, j=1: n\)</span><span class="math notranslate nohighlight">\(
Here we note that the indices for the entries in \)</span>K<span class="math notranslate nohighlight">\( are given un a
special way. For example, if \)</span>k=1, K \in \mathbb{R}^{3 \times 3}<span class="math notranslate nohighlight">\(, and
\)</span><span class="math notranslate nohighlight">\(K=\left(\begin{array}{ccc}
K_{-1,-1} &amp; K_{-1,0} &amp; K_{-1,1} \\
K_{0,-1} &amp; K_{0,0} &amp; K_{0,1} \\
K_{1,-1} &amp; K_{1,0} &amp; K_{1,1}
\end{array}\right)\)</span><span class="math notranslate nohighlight">\( for we may have the following 2D Laplacian kernel
\)</span><span class="math notranslate nohighlight">\(K=\left(\begin{array}{ccc}
0 &amp; -1 &amp; 0 \\
-1 &amp; 4 &amp; -1 \\
0 &amp; -1 &amp; 0
\end{array}\right)\)</span><span class="math notranslate nohighlight">\( The coefficients in (1.17) constitute a kernel
matrix \)</span><span class="math notranslate nohighlight">\(K \in \mathbb{R}^{(2 k+1) \times(2 k+1)}\)</span><span class="math notranslate nohighlight">\( where \)</span>k<span class="math notranslate nohighlight">\( is often
taken as a small integer. Here padding means how \)</span>g_{i+p, j+q}<span class="math notranslate nohighlight">\( is
defined when \)</span>(i+p, j+q)<span class="math notranslate nohighlight">\( is out of \)</span>1: m<span class="math notranslate nohighlight">\( or \)</span>1: n<span class="math notranslate nohighlight">\(. The following
three choices are often used \)</span><span class="math notranslate nohighlight">\(g_{i+p, j+q}=\left\{\begin{array}{lll}
0, &amp; &amp; \text { zero padding, } \\
f_{(i+p)} &amp; (\bmod m),(s+q) &amp; (\bmod n), &amp; \text { periodic padding } \\
f_{|i-1+p|,|j-1+q|}, &amp; &amp; \text { reflected padding }
\end{array}\right.\)</span><span class="math notranslate nohighlight">\( if
\)</span><span class="math notranslate nohighlight">\(i+p \notin\{1,2, \ldots, m\} \text { or } j+q \notin\{1,2, \ldots, n\}\)</span><span class="math notranslate nohighlight">\(
Here \)</span>d(\bmod m) \in{1, \cdots, m}<span class="math notranslate nohighlight">\( means the remainder when \)</span>d<span class="math notranslate nohighlight">\( is
divided by \)</span>m$.</p>
<p>Here is a diagram for convolution with one channel (and also stride
one).</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-05" />{width=”\textwidth”}</p>
</div>
<div class="section" id="convolution-with-stride-one-channel">
<h3>Convolution with stride (one channel)<a class="headerlink" href="#convolution-with-stride-one-channel" title="Permalink to this headline">¶</a></h3>
<p>Definition 2. Convolution with stride 2 is defined as
$<span class="math notranslate nohighlight">\(\left[K *_{2} g\right]_{i, j}=\sum_{p, q=-k}^{k} K_{p, q} g_{2 i+p-1,2 j+q-1}, \quad i=1:\left\lfloor\frac{m+1}{2}\right\rfloor, j=1:\left\lfloor\frac{n+1}{2}\right\rfloor\)</span><span class="math notranslate nohighlight">\(
We note that, in general, for any given integer \)</span>s \geq 1<span class="math notranslate nohighlight">\(, a
convolution with stride \)</span>s<span class="math notranslate nohighlight">\( for \)</span>g \in \mathbb{R}^{m \times n}<span class="math notranslate nohighlight">\( can be
defined as:
\)</span><span class="math notranslate nohighlight">\(\left[K *_{s} g\right]_{i, j}=\sum_{p, q=-k}^{k} K_{p, q} g_{s(i-11)+p+1, s(j-1)+q+1}, \quad i=1:\left\lfloor\frac{m+1}{s}\right\rfloor, j=1:\left\lfloor\frac{n+1}{s}\right\rfloor .\)</span><span class="math notranslate nohighlight">\(
Here \)</span>\left\lfloor\frac{m}{s}\right\rfloor<span class="math notranslate nohighlight">\( denotes the biggest integer
that less than \)</span>\frac{m}{s}$. The following is a diagram for stride 2 .</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-05(1)" />{width=”\textwidth”}</p>
<p>Lemma 1. The convolution with stride 2 can be written as:
$<span class="math notranslate nohighlight">\(K *_{2} g=\mathcal{S}(K * g),\)</span><span class="math notranslate nohighlight">\( where \)</span>\mathcal{S}<span class="math notranslate nohighlight">\( is a stride
operator defined by:
\)</span><span class="math notranslate nohighlight">\(\mathcal{S}: \mathbb{R}^{m \times n} \mapsto \mathbb{R}^{\frac{m+1}{2} \times \frac{n+1}{2}},\)</span><span class="math notranslate nohighlight">\(
with
\)</span><span class="math notranslate nohighlight">\([\mathcal{S}(g)]_{i, j}=g_{2 i-1,2 j-1}, \quad i=1:\left\lfloor\frac{m+1}{2}\right\rfloor, j=1:\left\lfloor\frac{n+1}{2}\right\rfloor\)</span><span class="math notranslate nohighlight">\(
Example 1. The so-called average pooling with kernel size \)</span>3 \times 3<span class="math notranslate nohighlight">\(
and stride 2 means \)</span><span class="math notranslate nohighlight">\(K *_{2},\)</span><span class="math notranslate nohighlight">\( where
\)</span><span class="math notranslate nohighlight">\(K=\frac{1}{9}\left(\begin{array}{lll}
1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1 \\
1 &amp; 1 &amp; 1
\end{array}\right)\)</span>$</p>
</div>
<div class="section" id="convolutional-operations-with-multi-channel">
<h3>Convolutional operations with multi-channel<a class="headerlink" href="#convolutional-operations-with-multi-channel" title="Permalink to this headline">¶</a></h3>
<p>One important class of linear mapping is the so-called convolution:
$<span class="math notranslate nohighlight">\(\theta: \mathbb{R}^{c \times m \times n} \mapsto \mathbb{R}^{h \times m \times n},\)</span><span class="math notranslate nohighlight">\(
where \)</span>m \times n<span class="math notranslate nohighlight">\( is called the spatial dimension or resolution, \)</span>c<span class="math notranslate nohighlight">\(
and \)</span>h<span class="math notranslate nohighlight">\( are corresponding to input and output channels. The operation is
defined by
\)</span><span class="math notranslate nohighlight">\([\theta(f)]_{s}=\sum_{t=1}^{c} K_{s, t} *[f]_{t}+b_{s} \mathbf{1} \in \mathbb{R}^{m \times n}, \quad s=1: h,\)</span><span class="math notranslate nohighlight">\(
where \)</span>1 \in \mathbb{R}^{m \times n}<span class="math notranslate nohighlight">\( is a \)</span>m \times n<span class="math notranslate nohighlight">\( matrix with all
elements being 1 , and for \)</span>[f], \in \mathbb{R}^{m \times n}<span class="math notranslate nohighlight">\( represent
for the \)</span>t<span class="math notranslate nohighlight">\(-th channel
\)</span><span class="math notranslate nohighlight">\(\left[K_{s, t} *[f]_{t}\right]_{i, j}=\sum_{p, q=-k}^{k} K_{s, t ; p, q} f_{t ; i+p, j+q}, \quad i=1: m, j=1: n\)</span><span class="math notranslate nohighlight">\(
The coefficients kernel \)</span>K_{s, t}<span class="math notranslate nohighlight">\( in (1.17) constitute a kernel matrix
\)</span><span class="math notranslate nohighlight">\(K_{s, t} \in \mathbb{R}^{(2 k+1) \times(2 k+1)}\)</span><span class="math notranslate nohighlight">\( where \)</span>k$ is often
taken as small integers.</p>
<p>Here a more compact notation for multi-channel convolution can be
written as $<span class="math notranslate nohighlight">\(\theta(f)=K * f+\mathbf{b}\)</span><span class="math notranslate nohighlight">\( where
\)</span><span class="math notranslate nohighlight">\(f=\left(\begin{array}{c}
{[f]_{1}} \\
{[f]_{2}} \\
\vdots \\
{[f]_{c}}
\end{array}\right), \quad K=\left(\begin{array}{cccc}
K_{1,1} &amp; K_{1,2} &amp; \cdots &amp; K_{1, c} \\
K_{2,1} &amp; K_{2,2} &amp; \cdots &amp; K_{2, c} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
K_{h, 1} &amp; K_{h, 2} &amp; \cdots &amp; K_{h, c}
\end{array}\right), \quad \mathbf{b}=\left(\begin{array}{c}
b_{1} \mathbf{1} \\
b_{2} \mathbf{1} \\
\vdots \\
b_{h} \mathbf{1}
\end{array}\right)=b \otimes 1\)</span><span class="math notranslate nohighlight">\( Furthermore, we have the following
natural extension of convolution with stride for multi-channel by
\)</span><span class="math notranslate nohighlight">\([\theta(f)]_{s}=\sum_{t=1}^{c} K_{s, t} *_{2}[f]_{t}+b_{s} 1 \in \mathbb{R}^{\tilde{m} \times \tilde{n}}, \quad s=1: h,\)</span><span class="math notranslate nohighlight">\(
where
\)</span><span class="math notranslate nohighlight">\(\tilde{m}=\left\lfloor\frac{m+1}{2}\right\rfloor, \quad \tilde{n}=\left\lfloor\frac{n+1}{2}\right\rfloor\)</span>$</p>
</div>
<div class="section" id="pooling-operation-in-cnns">
<h3>Pooling operation in CNNs<a class="headerlink" href="#pooling-operation-in-cnns" title="Permalink to this headline">¶</a></h3>
<p>Finally, we introduce another type of important operation in CNNs -
pooling. The key purpose for pooling operator is to reduce the spatial
resolution of images (features) in a typical CNN models. Basically,
pooling is an operator
$<span class="math notranslate nohighlight">\(T: \mathbb{R}^{c_{1} \times m_{1} \times n_{1}} \mapsto \mathbb{R}^{c_{2} \times m_{2} \times n_{2}} .\)</span><span class="math notranslate nohighlight">\(
where
\)</span><span class="math notranslate nohighlight">\(m_{2}=\left\lfloor\frac{m+1}{s}\right\rfloor, \quad n_{2}=\left\lfloor\frac{n+1}{s}\right\rfloor\)</span><span class="math notranslate nohighlight">\(
for any choice of \)</span>c_{2} \geq 1<span class="math notranslate nohighlight">\(. Here \)</span>s$ is also called the stride in
pooling operations. There are generally two types of pooling</p>
</div>
</div>
</div>
<div class="section" id="convolution-with-stride-s-as-pooling">
<h1>Convolution with stride s as pooling<a class="headerlink" href="#convolution-with-stride-s-as-pooling" title="Permalink to this headline">¶</a></h1>
<p>In this case, it often happens that
$<span class="math notranslate nohighlight">\(T=R *_{s}, \quad(s=2 \text { for the main case }) .\)</span><span class="math notranslate nohighlight">\( Here \)</span>R$ can be
learned or fixed such as average pooling as we discussed before.</p>
</div>
<div class="section" id="nonlinear-pooling">
<h1>Nonlinear pooling<a class="headerlink" href="#nonlinear-pooling" title="Permalink to this headline">¶</a></h1>
<p>The most commonly used nonlinear pooling is called max-pooling, a max
pooling with kernel size <span class="math notranslate nohighlight">\((2 k+1) \times(2 k+1)\)</span> and stride <span class="math notranslate nohighlight">\(s\)</span> is is
defined as
$<span class="math notranslate nohighlight">\(\left[R_{\max }(f)\right]_{t ; i, j}=\max \left\{f_{t ; s i+p-1, s j+q-1} \mid-k \leq p, q \leq k\right\}\)</span><span class="math notranslate nohighlight">\(
here \)</span>t<span class="math notranslate nohighlight">\( means channel and \)</span>c_{2}=c_{1}$ in this case.</p>
<p>Here is an example for max-pooling with kernel size <span class="math notranslate nohighlight">\(2 \times 2\)</span> and
stride 2 .</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-07" />{width=”\textwidth”}</p>
<div class="section" id="examples-of-convolution-filters-and-performance">
<h2>Examples of convolution filters and performance<a class="headerlink" href="#examples-of-convolution-filters-and-performance" title="Permalink to this headline">¶</a></h2>
<p>In this section, we will give a brief description how convolution
operations are used for image processing. One useful description can be
found in the following link:</p>
<p><a class="reference external" href="http://aishack.in/tutorials/image-convolution-examples/">http://aishack.in/tutorials/image-convolution-examples/</a></p>
<p>Convolutions is a technique for general signal processing. People
studying electrical/electronics will tell you the near infinite
sleepless nights these convolutions have given them. Entire books have
been written on this topic. And the questions and theorems that need to
be proved are [insurmountable]. But for computer vision, we’ll just
deal with some simple things.</p>
<p>A convolution lets you do many things, like calculate derivatives,
detect edges, apply blurs, etc. A very wide variety of things. And all
of this is done with a “convolution kernel”</p>
<div class="section" id="calculation-with-convolutions">
<h3>Calculation with convolutions<a class="headerlink" href="#calculation-with-convolutions" title="Permalink to this headline">¶</a></h3>
<p>The most direct way to compute a convolution would be to use multiple
for loops. But that causes a lot of repeated calculations. And as the
size of the image and kernel increases, the time to compute the
convolution increases too (quite drastically).</p>
<p>Techniques haves been developed to calculate convolutions rapidly. One
such technique is using the Discrete Fourier Transform. It converts the
entire convolution operation into a simple multiplication. Fortunately,
you don’t need to know the math to do this in OpenCV. It automatically
decides whether to do it in frequency domain (after the DFT) or not.</p>
</div>
<div class="section" id="image-convolution-examples">
<h3>Image convolution examples<a class="headerlink" href="#image-convolution-examples" title="Permalink to this headline">¶</a></h3>
<p>A convolution is very useful for signal processing in general. There is
a lot of complex mathematical theory available for convolutions. For
digital image processing, you don’t have to understand all of that. You
can use a simple matrix as an image convolution kernel and do some
interesting things!</p>
</div>
<div class="section" id="line-detection-by-1d-laplacian">
<h3>Line detection by 1D Laplacian<a class="headerlink" href="#line-detection-by-1d-laplacian" title="Permalink to this headline">¶</a></h3>
<p>With image convolutions, you can easily detect lines. Here are four
convolutions to detect horizontal, vertical and lines at 45 degrees:</p>
<p>Here’s <span class="math notranslate nohighlight">\(0,90,45,135\)</span> lines detection that I got on an image:
$<span class="math notranslate nohighlight">\(\begin{array}{|c|c|c|}
\hline-1 &amp; -1 &amp; -1 \\
\hline 2 &amp; 2 &amp; 2 \\
\hline-1 &amp; -1 &amp; -1 \\
\hline
\end{array}\)</span><span class="math notranslate nohighlight">\( \)</span><span class="math notranslate nohighlight">\(\begin{array}{|c|c|c|}
\hline-1 &amp; 2 &amp; -1 \\
\hline-1 &amp; 2 &amp; -1 \\
\hline-1 &amp; 2 &amp; -1 \\
\hline
\end{array}\)</span><span class="math notranslate nohighlight">\( \)</span><span class="math notranslate nohighlight">\(\begin{array}{|c|c|c|}
\hline-1 &amp; -1 &amp; 2 \\
\hline-1 &amp; 2 &amp; -1 \\
\hline 2 &amp; -1 &amp; -1 \\
\hline
\end{array}\)</span>$
<img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-09" />{width=”\textwidth”}</p>
<p>(a) image $<span class="math notranslate nohighlight">\(\left(\begin{array}{ccc}
-1 &amp; -1 &amp; -1 \\
2 &amp; 2 &amp; 2 \\
-1 &amp; -1 &amp; -1
\end{array}\right)\)</span>$ (b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-09(1)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-09(2)" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-09(3)" />{width=”\textwidth”}</p>
<p>(e) result</p>
<p>Fig. 1.2. A horizontal line detection done with convolutions</p>
<p>In Lena, the black background is the original result, the white
background is obtained by subtracting the original result from 255, the
same below.</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-10" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-10(1)" />{width=”\textwidth”}</p>
<p>(d) image
<span class="math notranslate nohighlight">\(\left(\begin{array}{lll}-1 &amp; 2 &amp; -1 \\ -1 &amp; 2 &amp; -1 \\ -1 &amp; 2 &amp; -1\end{array}\right)\)</span></p>
<p>(b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-10(2)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-10(3)" />{width=”\textwidth”}</p>
<p>(e) result</p>
<p>Fig. 1.3. A vertical line detection done with convolutions</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-10(4)" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-10(5)" />{width=”\textwidth”}</p>
<p>(b) filter (c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-10(6)" />{width=”\textwidth”}</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-11" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-11(1)" />{width=”\textwidth”}</p>
<p>(e) result</p>
<p>Fig. 1.4. A 45 degress line detection done with convolutions</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-11(2)" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-11(3)" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-11(4)" />{width=”\textwidth”}</p>
<p>(b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-11(5)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p>Fig. 1.5. A 135 degress line detection done with convolutions</p>
</div>
<div class="section" id="edge-detection-by-2d-laplacian-operator">
<h3>Edge detection by 2D Laplacian operator<a class="headerlink" href="#edge-detection-by-2d-laplacian-operator" title="Permalink to this headline">¶</a></h3>
<p>The laplacian is the second derivative of the image. It is extremely
sensitive to noise, so it isn’t used as much as other operators. Unless,
of course you have specific requirements.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>0     $-1$    0
</pre></div>
</div>
<hr class="docutils" />
<p><span class="math notranslate nohighlight">\(-1\)</span>    4     <span class="math notranslate nohighlight">\(-1\)</span>
0     <span class="math notranslate nohighlight">\(-1\)</span>    0</p>
<p><span class="math notranslate nohighlight">\(-1\)</span>   <span class="math notranslate nohighlight">\(-1\)</span>   <span class="math notranslate nohighlight">\(-1\)</span></p>
<hr class="docutils" />
<p><span class="math notranslate nohighlight">\(-1\)</span>    8     <span class="math notranslate nohighlight">\(-1\)</span>
<span class="math notranslate nohighlight">\(-1\)</span>   <span class="math notranslate nohighlight">\(-1\)</span>   <span class="math notranslate nohighlight">\(-1\)</span></p>
<p>The laplacian operator</p>
<p>(include diagonals)</p>
<p>Here’s the result with the convolution kernel without diagonals:</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-12" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-12(1)" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-12(2)" />{width=”\textwidth”}</p>
<p>(b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-12(3)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p>Fig. 1.6. A laplace operator done with convolutions</p>
<p>The result with the convolution kernel with diagonals:</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-13" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-13(1)" />{width=”\textwidth”}</p>
<p>(d) image $<span class="math notranslate nohighlight">\(\left(\begin{array}{ccc}
-1 &amp; -1 &amp; -1 \\
-1 &amp; 8 &amp; -1 \\
-1 &amp; -1 &amp; -1
\end{array}\right)\)</span>$ (b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-13(2)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-13(3)" />{width=”\textwidth”}</p>
<p>(e) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-13(4)" />{width=”\textwidth”}</p>
<p>Fig. 1.7. A laplace operator include diagonals done with convolutions</p>
</div>
<div class="section" id="the-laplacian-of-gaussian">
<h3>The Laplacian of Gaussian<a class="headerlink" href="#the-laplacian-of-gaussian" title="Permalink to this headline">¶</a></h3>
<p>The laplacian alone has the disadvantage of being extremely sensitive to
noise. So, smoothing the image before a laplacian improves the results
we get. This is done with a <span class="math notranslate nohighlight">\(5 \times 5\)</span> image convolution kernel.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>0      0     $-1$    0      0
</pre></div>
</div>
<hr class="docutils" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>0     $-1$   $-2$   $-1$    0
</pre></div>
</div>
<p><span class="math notranslate nohighlight">\(-1\)</span>   <span class="math notranslate nohighlight">\(-2\)</span>    16    <span class="math notranslate nohighlight">\(-2\)</span>   <span class="math notranslate nohighlight">\(-1\)</span>
0     <span class="math notranslate nohighlight">\(-1\)</span>   <span class="math notranslate nohighlight">\(-2\)</span>   <span class="math notranslate nohighlight">\(-1\)</span>    0
0      0     <span class="math notranslate nohighlight">\(-1\)</span>    0      0</p>
<p>The result on applying this image convolution was:</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-14" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-14(1)" />{width=”\textwidth”}</p>
<p>(d) image<br />
<img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-14(2)" />{width=”\textwidth”}</p>
<p>(b) filter</p>
<p>(c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-14(3)" />{width=”\textwidth”}<br />
<img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-14(4)" />{width=”\textwidth”}</p>
<p>Fig. 1.8. A Laplacian of Gaussian operator done with convolutions</p>
</div>
<div class="section" id="other-examples-with-relu-activation">
<h3>Other examples with ReLU activation<a class="headerlink" href="#other-examples-with-relu-activation" title="Permalink to this headline">¶</a></h3>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-15" />{width=”\textwidth”}
$<span class="math notranslate nohighlight">\(\left(\begin{array}{ccccc}
0 &amp; 0 &amp; -1 &amp; 0 &amp; 0 \\
0 &amp; -1 &amp; -2 &amp; -1 &amp; 0 \\
-1 &amp; -2 &amp; 16 &amp; -2 &amp; -1 \\
0 &amp; -1 &amp; -2 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 0 &amp; 0
\end{array}\right)\)</span>$ (b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-15(1)" />{width=”\textwidth”}</p>
<p>(c) convolution result</p>
<p>(a) input image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-15(2)" />{width=”\textwidth”}</p>
<p>(d) result after ReLU
<span class="math notranslate nohighlight">\(\left(\begin{array}{lll}\frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \\ \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \\ \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9}\end{array}\right)\)</span></p>
<p>(e) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-15(3)" />{width=”\textwidth”}</p>
<p>(f) result after average</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-15(4)" />{width=”\textwidth”}</p>
<p>(g) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-15(5)" />{width=”\textwidth”}</p>
<p>(j) ReLU $<span class="math notranslate nohighlight">\(\left(\begin{array}{ccccc}
0 &amp; 0 &amp; -1 &amp; 0 &amp; 0 \\
0 &amp; -1 &amp; -2 &amp; -1 &amp; 0 \\
-1 &amp; -2 &amp; 16 &amp; -2 &amp; -1 \\
0 &amp; -1 &amp; -2 &amp; -1 &amp; 0 \\
0 &amp; 0 &amp; -1 &amp; 0 &amp; 0
\end{array}\right)\)</span>$ (h) filter</p>
<p><span class="math notranslate nohighlight">\(\left(\begin{array}{lll}\frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \\ \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9} \\ \frac{1}{9} &amp; \frac{1}{9} &amp; \frac{1}{9}\end{array}\right)\)</span></p>
<p>(k) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-15(6)" />{width=”\textwidth”}</p>
<p>(1) average</p>
</div>
<div class="section" id="some-other-examples">
<h3>Some other examples<a class="headerlink" href="#some-other-examples" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>
<div class="section" id="edge-detection">
<h1>Edge detection<a class="headerlink" href="#edge-detection" title="Permalink to this headline">¶</a></h1>
<p>The above kernels are in a way edge detectors. Only thing is that they
have separate components for horizontal and vertical lines. A way to
“combine” the results is to merge the convolution kernels. The new image
convolution kernel looks like this:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$-1$ $-1$   $-1$
</pre></div>
</div>
<hr class="docutils" />
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>$-1$ 8      $-1$
$-1$ $-1$   $-1$
</pre></div>
</div>
<p>Below result I got with edge detection:</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-16" />{width=”\textwidth”}</p>
<p>(m) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-16(1)" />{width=”\textwidth”}</p>
<p>(p) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-16(2)" />{width=”\textwidth”}</p>
<p>(n) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-16(3)" />{width=”\textwidth”}</p>
<p>(o) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-16(4)" />{width=”\textwidth”}</p>
<p>(q) result</p>
<p>Fig. 1.9. A edge detection done with convolutions</p>
</div>
<div class="section" id="the-sobel-edge-operator">
<h1>The Sobel Edge Operator<a class="headerlink" href="#the-sobel-edge-operator" title="Permalink to this headline">¶</a></h1>
<p>The above operators are very prone to noise. The Sobel edge operators
have a smoothing effect, so they’re less affected to noise. Again,
there’s a horizontal component and a vertical component.</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-17" />{width=”\textwidth”}</p>
<p>[|c|c|c|]{} <span class="math notranslate nohighlight">\(-1\)</span> &amp; <span class="math notranslate nohighlight">\(-2\)</span> &amp; <span class="math notranslate nohighlight">\(-1\)</span> &amp; &amp;<br />
0 &amp; 0 &amp; 0 &amp; &amp;<br />
1 &amp; 2 &amp; 1 &amp; &amp;<br />
&amp; <span class="math notranslate nohighlight">\(-1\)</span> &amp; 0 &amp; 1<br />
<span class="math notranslate nohighlight">\(-2\)</span> &amp; 0 &amp; 2 &amp; &amp;<br />
<span class="math notranslate nohighlight">\(-1\)</span> &amp; 0 &amp; 1 &amp; &amp;\</p>
<p>On applying horizontal component in image, the result was:</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-17(1)" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-17(2)" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-17(3)" />{width=”\textwidth”}</p>
<p>(b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-17(4)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-17(5)" />{width=”\textwidth”}</p>
<p>(e) result</p>
<p>Fig. 1.10. A horizontal sobel edge operator done with convolutions</p>
<p>On applying vertical component in image, the result was:</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-18" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-18(1)" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-18(2)" />{width=”\textwidth”}
$<span class="math notranslate nohighlight">\(\left(\begin{array}{lll}
-1 &amp; 0 &amp; 1 \\
-2 &amp; 0 &amp; 2 \\
-1 &amp; 0 &amp; 1
\end{array}\right)\)</span>$ (b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-18(3)" />{width=”\textwidth”}</p>
<p>(c) result<br />
<img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-18(4)" />{width=”\textwidth”}</p>
<p>(e) result</p>
<p>Fig. 1.11. A vertical sobel edge operator done with convolutions</p>
<p>Fig. 1.11. A vertical sobel edge operator done with convolutions</p>
</div>
<div class="section" id="simple-box-blur">
<h1>Simple box blur<a class="headerlink" href="#simple-box-blur" title="Permalink to this headline">¶</a></h1>
<p><span class="math notranslate nohighlight">\({ }^{1}\)</span> Here’s a first and simplest. This convolution kernel has an
averaging effect. So you end up with a slight blur. The image
convolution kernel is: $<span class="math notranslate nohighlight">\(\begin{array}{|l|l|l|}
\hline 1 / 9 &amp; 1 / 9 &amp; 1 / 9 \\
\hline 1 / 9 &amp; 1 / 9 &amp; 1 / 9 \\
\hline 1 / 9 &amp; 1 / 9 &amp; 1 / 9 \\
\hline
\end{array}\)</span><span class="math notranslate nohighlight">\( Note that the sum of all elements of this matrix is \)</span>1.0$.
This is important. If the sum is not exactly one, the resultant image
will be brighter or darker.</p>
<p>Here’s a blur that I got on an image:</p>
<p><span class="math notranslate nohighlight">\(\overline{{ }^{1} \text { The following examples are from the website, http://aishack.in/tutorials/image- }}\)</span>
convolution-examples/</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-19" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-19(1)" />{width=”\textwidth”}</p>
<p>(b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-19(2)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-19(3)" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-19(4)" />{width=”\textwidth”}</p>
<p>(e) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-19(5)" />{width=”\textwidth”}</p>
<p>(f) result</p>
<p>Fig. 1.12. A simple blur done with convolutions</p>
</div>
<div class="section" id="gaussian-blur">
<h1>Gaussian blur<a class="headerlink" href="#gaussian-blur" title="Permalink to this headline">¶</a></h1>
<p>Gaussian blur has certain mathematical properties that makes it
important for computer vision. And you can approximate it with an image
convolution. The image convolution kernel for a Gaussian blur is:</p>
<p>0   0    0     5     0     0    0</p>
<hr class="docutils" />
<p>0   5    18    32    18    5    0
0   18   64    100   64    18   0
5   32   100   100   100   32   5
0   18   64    100   64    18   0
0   5    18    32    18    5    0
0   0    0     5     0     0    0</p>
<p>Here’s a result that I got:</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-20" />{width=”\textwidth”}</p>
<p>(a) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-20(1)" />{width=”\textwidth”}</p>
<p>(d) image</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-20(2)" />{width=”\textwidth”}</p>
<p>(b) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-20(3)" />{width=”\textwidth”}</p>
<p>(e) filter</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-20(4)" />{width=”\textwidth”}</p>
<p>(c) result</p>
<p><img alt="image" src="Module4/m4_02/2022_01_06_b5ce182ed1bd5f482e5bg-20(5)" />{width=”\textwidth”}</p>
<p>(f) result</p>
<p>Fig. 1.13. A Gaussian blur done with convolutions</p>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>You got to know about some important operations that can be approximated
using an image convolution. You learned the exact convolution kernels
used and also saw an example of how each operator modifies an image. I
hope this helped!</p>
</div>
</div>
<div class="section" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h1>
<p>[1] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei.
Imagenet: A largescale hierarchical image database. In 2009 IEEE
conference on computer vision and pattern recognition, pages 248-255.
Ieee, 2009.</p>
<p>[2] J. He, Y. Chen, and J. Xu. Constrained linear data-feature mapping
for image classification. arXiv preprint arXiv: <span class="math notranslate nohighlight">\(1911.10428,2019 .\)</span></p>
<p>[3] <span class="math notranslate nohighlight">\(\mathrm{K}\)</span>. He, X. Zhang, S. Ren, and J. Sun. Deep residual
learning for image recognition. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pages 770-778, 2016 .</p>
<p>[4] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep
residual networks. In European Conference on Computer Vision, pages
630-645. Springer, <span class="math notranslate nohighlight">\(2016 .\)</span></p>
<p>[5] A. Krizhevsky and G. Hinton. Learning multiple layers of features
from tiny images. Technical report, Citeseer, <span class="math notranslate nohighlight">\(2009 .\)</span></p>
<p>[6] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet
classification with deep convolutional neural networks. In Advances in
neural information processing systems, pages <span class="math notranslate nohighlight">\(1097-1105,2012\)</span>.</p>
<p>[7] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based
learning applied to document recognition. Proceedings of the IEEE,
<span class="math notranslate nohighlight">\(86(11): 2278-2324,1998 .\)</span></p>
<p>[8] K. Simonyan and A. Zisserman. Very deep convolutional networks for
largescale image recognition. arXiv preprint arXiv: <span class="math notranslate nohighlight">\(1409.1556,2014 .\)</span></p>
<p>[9] J. Xu and L. Zikatanov. Algebraic multigrid methods. Acta
Numerica, 26:591<span class="math notranslate nohighlight">\(721,2017 .\)</span></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "liuzhengqi1996/math452_Spring2022",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Module4/m4_02"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../m4_01/m4_01.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Contents</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="../m4_03/m4_03.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Contents</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Department of Mathematics, Penn State University Park<br/>
        
            &copy; Copyright The Pennsylvania State University, 2021. This material is not licensed for resale.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>